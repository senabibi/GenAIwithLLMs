{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!!pip install litellm\n",
        "\n",
        "# Important!!!\n",
        "#\n",
        "# <---- Set your 'OPENAI_API_KEY' as a secret over there with the \"key\" icon\n",
        "#\n",
        "#\n",
        "import os\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ],
      "metadata": {
        "id": "KEYrzG2vB8Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mwe2eeOQB0cC",
        "outputId": "07254cd4-e623-4ec7-99bb-794b2f975d1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What would you like me to do? read each of the files in the current directory and tell me what they do\n",
            "Executing: list_files with args {}\n",
            "Result: {'result': ['.config', 'sample_data']}\n",
            "Executing: read_file with args {'file_name': '.config'}\n",
            "Result: {'result': \"Error: [Errno 21] Is a directory: '.config'\"}\n",
            "Termination message: It seems that \".config\" is a directory, not a file. If you want specific information from within it, please let me know, or ensure there are files inside it to read.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "from typing import List\n",
        "\n",
        "from litellm import completion\n",
        "\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def terminate(message: str) -> None:\n",
        "    \"\"\"Terminate the agent loop and provide a summary message.\"\"\"\n",
        "    print(f\"Termination message: {message}\")\n",
        "\n",
        "tool_functions = {\n",
        "    \"list_files\": list_files,\n",
        "    \"read_file\": read_file,\n",
        "    \"terminate\": terminate\n",
        "}\n",
        "\n",
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"list_files\",\n",
        "            \"description\": \"Returns a list of files in the directory.\",\n",
        "            \"parameters\": {\"type\": \"object\", \"properties\": {}, \"required\": []}\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"read_file\",\n",
        "            \"description\": \"Reads the content of a specified file in the directory.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\"file_name\": {\"type\": \"string\"}},\n",
        "                \"required\": [\"file_name\"]\n",
        "            }\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\": {\n",
        "            \"name\": \"terminate\",\n",
        "            \"description\": \"Terminates the conversation. No further actions or interactions are possible after this. Prints the provided message for the user.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"message\": {\"type\": \"string\"},\n",
        "                },\n",
        "                \"required\": [\"message\"]\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "agent_rules = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "You are an AI agent that can perform tasks by using available tools.\n",
        "\n",
        "If a user asks about files, documents, or content, first list the files before reading them.\n",
        "\n",
        "When you are done, terminate the conversation by using the \"terminate\" tool and I will provide the results to the user.\n",
        "\"\"\"\n",
        "}]\n",
        "\n",
        "# Initialize agent parameters\n",
        "iterations = 0\n",
        "max_iterations = 10\n",
        "\n",
        "user_task = input(\"What would you like me to do? \")\n",
        "\n",
        "memory = [{\"role\": \"user\", \"content\": user_task}]\n",
        "\n",
        "# The Agent Loop\n",
        "while iterations < max_iterations:\n",
        "\n",
        "    messages = agent_rules + memory\n",
        "\n",
        "    response = completion(\n",
        "        model=\"openai/gpt-4o\",\n",
        "        messages=messages,\n",
        "        tools=tools,\n",
        "        max_tokens=1024\n",
        "    )\n",
        "\n",
        "    if response.choices[0].message.tool_calls:\n",
        "        tool = response.choices[0].message.tool_calls[0]\n",
        "        tool_name = tool.function.name\n",
        "        tool_args = json.loads(tool.function.arguments)\n",
        "\n",
        "        action = {\n",
        "            \"tool_name\": tool_name,\n",
        "            \"args\": tool_args\n",
        "        }\n",
        "\n",
        "        if tool_name == \"terminate\":\n",
        "            print(f\"Termination message: {tool_args['message']}\")\n",
        "            break\n",
        "        elif tool_name in tool_functions:\n",
        "            try:\n",
        "                result = {\"result\": tool_functions[tool_name](**tool_args)}\n",
        "            except Exception as e:\n",
        "                result = {\"error\":f\"Error executing {tool_name}: {str(e)}\"}\n",
        "        else:\n",
        "            result = {\"error\": f\"Unknown tool: {tool_name}\"}\n",
        "\n",
        "        print(f\"Executing: {tool_name} with args {tool_args}\")\n",
        "        print(f\"Result: {result}\")\n",
        "        memory.extend([\n",
        "            {\"role\": \"assistant\", \"content\": json.dumps(action)},\n",
        "            {\"role\": \"user\", \"content\": json.dumps(result)}\n",
        "        ])\n",
        "    else:\n",
        "        result = response.choices[0].message.content\n",
        "        print(f\"Response: {result}\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting Up Your Simulation\n",
        "When starting a conversation with an LLM to simulate your agent, begin by establishing the framework. We can do this with a simple prompt in a chat interface. The prompt should clearly outline the agent’s goals, actions, and the simulation process. Here’s a template you can use:\n",
        "\n",
        "I'd like to simulate an AI agent that I'm designing. The agent will be built using these components:\n",
        "\n",
        "Goals: [List your goals]\n",
        "Actions: [List available actions]\n",
        "\n",
        "At each step, your output must be an action to take.\n",
        "\n",
        "Stop and wait and I will type in the result of\n",
        "the action as my next message.\n",
        "\n",
        "Ask me for the first task to perform.\n",
        "For a Proactive Coder agent, you might use the following prompt to kick-off a simulation in ChatGPT:\n",
        "\n",
        "I'd like to simulate an AI agent that I'm designing. The agent will be built using these components:\n",
        "\n",
        "Goals:\n",
        "* Find potential code enhancements\n",
        "* Ensure changes are small and self-contained\n",
        "* Get user approval before making changes\n",
        "* Maintain existing interfaces\n",
        "\n",
        "Actions available:\n",
        "* list_project_files()\n",
        "* read_project_file(filename)\n",
        "* ask_user_approval(proposal)\n",
        "* edit_project_file(filename, changes)\n",
        "\n",
        "At each step, your output must be an action to take.\n",
        "\n",
        "Stop and wait and I will type in the result of\n",
        "the action as my next message.\n",
        "\n",
        "Ask me for the first task to perform.\n",
        "Take a moment to open up ChatGPT and try out this prompt. You can use the same prompt in any chat interface that supports LLMs. What worked? What didn’t?\n",
        "\n",
        "Learning Through Agent Simulation\n",
        "Understanding Agent Reasoning\n",
        "When you begin simulating your agent’s behavior, you’re essentially conducting a series of experiments to understand how well it can reason with the tools and goals you’ve provided. Start by presenting a simple scenario – perhaps a small Python project with just a few files. Watch how the agent approaches the task. Does it immediately jump to reading files, or does it first list the available files to get an overview? These initial decisions reveal a lot about whether your goals and actions enable systematic problem-solving.\n",
        "\n",
        "As you observe the agent’s decisions, you’ll notice that the way you present information significantly impacts its reasoning. For instance, when you return the results of list_project_files(), you might first try returning just the filenames:\n",
        "\n",
        "[\"main.py\", \"utils.py\", \"data_processor.py\"]\n",
        "Then experiment with providing more context:\n",
        "\n",
        "{\n",
        "    \"files\": [\"main.py\", \"utils.py\", \"data_processor.py\"],\n",
        "    \"total_files\": 3,\n",
        "    \"directory\": \"/project\"\n",
        "}\n",
        "You might discover that the additional metadata helps the agent make more informed decisions about which files to examine next. This kind of experimentation with result formats helps you understand how much context your agent needs to reason effectively.\n",
        "\n",
        "Evolving Your Tools and Goals\n",
        "The simulation process often reveals that your initial tool descriptions aren’t as clear as you thought. For example, you might start with a simple description for read_project_file():\n",
        "\n",
        "read_project_file(filename) -> Returns the content of the specified file\n",
        "Through simulation, you might find the agent using it incorrectly, leading you to enhance the description:\n",
        "\n",
        "read_project_file(filename) -> Returns the content of a Python file from the project directory.\n",
        "The filename should be one previously returned by list_project_files().\n",
        "Similarly, your goals might evolve. You might start with “Find potential code enhancements” but discover through simulation that the agent needs more specific guidance. This might lead you to refine the goal to “Identify opportunities to improve error handling and input validation in functions.”\n",
        "\n",
        "Understanding Memory Through Chat\n",
        "One of the most enlightening aspects of simulation is realizing that the chat format naturally mimics the list-based memory system we use in our agent loop memory. Each exchange between you and the LLM represents an iteration of the agent loop and a new memory entry – the agent’s actions and the environment’s responses accumulate just as they would in our implemented memory system. This helps you understand how much history the agent can accumulate and still maintain context and make good decisions.\n",
        "\n",
        "Learning from Failures\n",
        "Introducing controlled chaos into your simulation provides valuable insights. Try returning error messages instead of successful results:\n",
        "\n",
        "{\"error\": \"FileNotFoundError: main.py does not exist\"}\n",
        "Or return malformed data:\n",
        "\n",
        "{\"cont3nt\": \"def broken_func(): pass\"}\n",
        "Watch how the agent handles these situations. Does it try alternative approaches? Does it give up too easily? Does it maintain its goal focus despite errors? These observations help you design better error handling and recovery strategies.\n",
        "\n",
        "Preventing Runaway Agents\n",
        "The simulation environment provides a safe space to test termination conditions. You can experiment with different criteria for when the agent should conclude its task. Perhaps it should stop after examining a certain number of files, or after making a specific number of improvement suggestions. The chat format lets you quickly try different approaches without worrying about infinite loops or resource consumption.\n",
        "\n",
        "Rapid Iteration and Improvement\n",
        "The true power of simulation lies in its speed. You can test dozens of scenarios in the time it would take to implement a single feature. Want to see how the agent handles a project with 100 files? Just tell it that’s what list_project_files() returned. Curious about how it would handle deeply nested function calls? Paste in some complex code and see how it analyzes it.\n",
        "\n",
        "Learning from the Agent\n",
        "At the end of your simulation sessions, ask the agent to reflect on its experience. What tools did it wish it had? Were any instructions unclear? Which goals were too vague? The LLM can often provide surprisingly insightful suggestions about how to improve your GAME design.\n",
        "\n",
        "For example, the agent might suggest: “The ask_user_approval() action would be more effective if it could include code snippets showing the proposed changes. This would help users make more informed decisions about the suggested improvements.”\n",
        "\n",
        "Building Your Example Library\n",
        "As you conduct these simulations, you’re building a valuable library of examples. When you see the agent make a particularly good decision, save that exchange. When it makes a poor choice, save that too. These examples become invaluable when you move to implementation – they can be used to craft better prompts and test cases.\n",
        "\n",
        "Keep a record of exchanges like this:\n",
        "\n",
        "Good Example:\n",
        "\n",
        "Agent: \"Before modifying utils.py, I should read its contents to understand the current error handling patterns.\"\n",
        "Action: read_project_file(\"utils.py\")\n",
        "Result: [file contents]\n",
        "Agent: \"I notice these functions lack input validation. I'll propose focused improvements for each function.\"\n",
        "Poor Example:\n",
        "\n",
        "Agent: \"I'll start editing all the files to add error handling.\"\n",
        "Action: edit_project_file(\"utils.py\", {...})\n",
        "[Missing analysis and user approval steps]\n",
        "These examples help you understand what patterns to encourage or discourage in your implemented agent.\n",
        "\n",
        "Through this iterative process of simulation, observation, and refinement, you develop a deep understanding of how your agent will behave in the real world. This understanding is invaluable when you move to implementation, helping you build agents that are more robust, more capable, and better aligned with your goals.\n",
        "\n",
        "Remember, the time spent in simulation is an investment that pays off in better design decisions and fewer implementation surprises. When you finally start coding, you’re not just hoping your design will work – you’ve already seen it work in hundreds of scenarios."
      ],
      "metadata": {
        "id": "QavBgbSkNT06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a Simple Agent Framework 1\n",
        "We are designing our agents in terms of GAME. Ideally, we would like our code to reflect how we design the agent, so that we can easily translate our design into an implementation. Also, we can see that the GAME components are what change from one agent to another while the core loop stays the same. We would like to design a framework that allows us to reuse as much as possible while making it easy to change the GAME pieces without affecting the GAME rules (e.g., the agent loop).\n",
        "\n",
        "At first, it will appear that we are adding complexity to the agent — and we are. However, this complexity is necessary to create a framework that is flexible and reusable. The goal is to create a framework that allows us to build agents quickly and easily without changing the core loop. We are going to look at each of the individual GAME component implementations and then how they fit into the overall framework at the end.\n",
        "\n",
        "G - Goals Implementation\n",
        "First, let’s create a simple goal class that defines what our agent is trying to accomplish:\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class Goal:\n",
        "    priority: int\n",
        "    name: str\n",
        "    description: str\n",
        "Goals will describe what we are trying to achieve and how to achieve it. By encapsulating them into objects, we can move away from large “walls of text” that represent the instructions for our agent. Additionally, we can add priority to our goals, which will help us decide which goal to pursue first and how to sort or format them when combining them into a prompt.\n",
        "\n",
        "We broadly use the term “goal” to encompass both “what” the agent is trying to achieve and “how” it should approach the task. This duality is crucial for guiding the agent’s behavior effectively. An important type of goal can be examples that show the agent how to reason in certain situations. We can also build goals that define core rules that are common across all agents in our system or that give it special instructions on how to solve certain types of tasks.\n",
        "\n",
        "Now, let’s take a look at how we might create a goal related to file management for our agent:\n",
        "\n",
        "from game.core import Goal\n",
        "\n",
        "# Define a simple file management goal\n",
        "file_management_goal = Goal(\n",
        "    priority=1,\n",
        "    name=\"file_management\",\n",
        "    description=\"\"\"Manage files in the current directory by:\n",
        "    1. Listing files when needed\n",
        "    2. Reading file contents when needed\n",
        "    3. Searching within files when information is required\n",
        "    4. Providing helpful explanations about file contents\"\"\"\n",
        ")\n",
        "A - Actions Implementation with JSON Schemas\n",
        "Actions define what the agent can do. Think of them as the agent’s toolkit. Each action is a discrete capability that can be executed in the environment. The action system has two main parts: the Action class and the ActionRegistry.\n",
        "\n",
        "The actions are the interface between our agent and its environment. These are descriptions of what the agent can do to affect the environment. We have previously built out actions using Python functions, but let’s encapsulate the parts of an action into an object:\n",
        "\n",
        "class Action:\n",
        "    def __init__(self,\n",
        "                 name: str,\n",
        "                 function: Callable,\n",
        "                 description: str,\n",
        "                 parameters: Dict,\n",
        "                 terminal: bool = False):\n",
        "        self.name = name\n",
        "        self.function = function\n",
        "        self.description = description\n",
        "        self.terminal = terminal\n",
        "        self.parameters = parameters\n",
        "\n",
        "    def execute(self, **args) -> Any:\n",
        "        \"\"\"Execute the action's function\"\"\"\n",
        "        return self.function(**args)\n",
        "At first, it may not appear that this is much different from the previous implementation. However, later, we will see that this makes it much easier to create different agents by simply swapping out the actions without having to modify the core loop.\n",
        "\n",
        "When the agent provides a response, it is going to return JSON. However, we are going to want a way to lookup the actual object associated with the action indicated by the JSON. To do this, we will create an ActionRegistry that will allow us to register actions and look them up by name:\n",
        "\n",
        "class ActionRegistry:\n",
        "    def __init__(self):\n",
        "        self.actions = {}\n",
        "\n",
        "    def register(self, action: Action):\n",
        "        self.actions[action.name] = action\n",
        "\n",
        "    def get_action(self, name: str) -> [Action, None]:\n",
        "        return self.actions.get(name, None)\n",
        "\n",
        "    def get_actions(self) -> List[Action]:\n",
        "        \"\"\"Get all registered actions\"\"\"\n",
        "        return list(self.actions.values())\n",
        "Here is an example of how we might define some actions for a file management agent:\n",
        "\n",
        "def list_files() -> list:\n",
        "    \"\"\"List all files in the current directory.\"\"\"\n",
        "    return os.listdir('.')\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read and return the contents of a file.\"\"\"\n",
        "    with open(file_name, 'r') as f:\n",
        "        return f.read()\n",
        "\n",
        "def search_in_file(file_name: str, search_term: str) -> list:\n",
        "    \"\"\"Search for a term in a file and return matching lines.\"\"\"\n",
        "    results = []\n",
        "    with open(file_name, 'r') as f:\n",
        "        for i, line in enumerate(f.readlines()):\n",
        "            if search_term in line:\n",
        "                results.append((i+1, line.strip()))\n",
        "    return results\n",
        "\n",
        "# Create and populate the action registry\n",
        "registry = ActionRegistry()\n",
        "\n",
        "registry.register(Action(\n",
        "    name=\"list_files\",\n",
        "    function=list_files,\n",
        "    description=\"List all files in the current directory\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {},\n",
        "        \"required\": []\n",
        "    },\n",
        "    terminal=False\n",
        "))\n",
        "\n",
        "registry.register(Action(\n",
        "    name=\"read_file\",\n",
        "    function=read_file,\n",
        "    description=\"Read the contents of a specific file\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"file_name\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Name of the file to read\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"file_name\"]\n",
        "    },\n",
        "    terminal=False\n",
        "))\n",
        "\n",
        "registry.register(Action(\n",
        "    name=\"search_in_file\",\n",
        "    function=search_in_file,\n",
        "    description=\"Search for a term in a specific file\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"file_name\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Name of the file to search in\"\n",
        "            },\n",
        "            \"search_term\": {\n",
        "                \"type\": \"string\",\n",
        "                \"description\": \"Term to search for\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"file_name\", \"search_term\"]\n",
        "    },\n",
        "    terminal=False\n",
        "))\n",
        "M - Memory Implementation\n",
        "Almost every agent needs to remember what happens from one loop iteration to the next. This is where the Memory component comes in. It allows the agent to store and retrieve information about its interactions, which is critical for context and decision-making. We can create a simple class to represent the memory:\n",
        "\n",
        "class Memory:\n",
        "    def __init__(self):\n",
        "        self.items = []  # Basic conversation histor\n",
        "\n",
        "    def add_memory(self, memory: dict):\n",
        "        \"\"\"Add memory to working memory\"\"\"\n",
        "        self.items.append(memory)\n",
        "\n",
        "    def get_memories(self, limit: int = None) -> List[Dict]:\n",
        "        \"\"\"Get formatted conversation history for prompt\"\"\"\n",
        "        return self.items[:limit]\n",
        "Originally, we just used a simple list of messages. Is it worth wrapping the list in this additional class? Yes, because it allows us to add additional functionality later without changing the core loop. For example, we might want to store the memory in a database and dynamically change what memories the agent sees at each loop iteration based on some analysis of the state of the memory. With this simple interface, we can create subclasses that implement different memory strategies without changing the core loop.\n",
        "\n",
        "One thing to note is that our memory always has to be represented as a list of messages in the prompt. Because of this, we provide a simple interface to the memory that returns the last N messages in the correct format. This allows us to keep the memory class agnostic to how it is used. We can change how we store the memory (e.g., in a database) without changing how we access it in the agent loop. Even if we store the memory in a complicated graph structure, we are still going to need to pass the memories to the LLM as a list and format them as messages.\n",
        "\n",
        "E - Environment Implementation\n",
        "In our original implementation, we hardcoded our “environment” interface as a series of if/else statements and function calls. We would like to have a more modular interface that allows us to execute actions without needing to know how they are implemented or have conditional logic in the loop. This is where the Environment component comes in. It serves as a bridge between the agent and the outside world, executing actions and returning results.\n",
        "\n",
        "class Environment:\n",
        "    def execute_action(self, action: Action, args: dict) -> dict:\n",
        "        \"\"\"Execute an action and return the result.\"\"\"\n",
        "        try:\n",
        "            result = action.execute(**args)\n",
        "            return self.format_result(result)\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                \"tool_executed\": False,\n",
        "                \"error\": str(e),\n",
        "                \"traceback\": traceback.format_exc()\n",
        "            }\n",
        "\n",
        "    def format_result(self, result: Any) -> dict:\n",
        "        \"\"\"Format the result with metadata.\"\"\"\n",
        "        return {\n",
        "            \"tool_executed\": True,\n",
        "            \"result\": result,\n",
        "            \"timestamp\": time.strftime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
        "        }"
      ],
      "metadata": {
        "id": "UMa-8e0DNctJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a Simple Agent Framework 2\n",
        "Now, we are going to put the components together into a reusable agent class. This class will encapsulate the GAME components and provide a simple interface for running the agent loop. The agent will be responsible for constructing prompts, executing actions, and managing memory. We can create different agents simply by changing the goals, actions, and environment without modifying the core loop.\n",
        "\n",
        "Let’s take a look at our agent class:\n",
        "\n",
        "class Agent:\n",
        "    def __init__(self,\n",
        "                 goals: List[Goal],\n",
        "                 agent_language: AgentLanguage,\n",
        "                 action_registry: ActionRegistry,\n",
        "                 generate_response: Callable[[Prompt], str],\n",
        "                 environment: Environment):\n",
        "        \"\"\"\n",
        "        Initialize an agent with its core GAME components\n",
        "        \"\"\"\n",
        "        self.goals = goals\n",
        "        self.generate_response = generate_response\n",
        "        self.agent_language = agent_language\n",
        "        self.actions = action_registry\n",
        "        self.environment = environment\n",
        "\n",
        "    def construct_prompt(self, goals: List[Goal], memory: Memory, actions: ActionRegistry) -> Prompt:\n",
        "        \"\"\"Build prompt with memory context\"\"\"\n",
        "        return self.agent_language.construct_prompt(\n",
        "            actions=actions.get_actions(),\n",
        "            environment=self.environment,\n",
        "            goals=goals,\n",
        "            memory=memory\n",
        "        )\n",
        "\n",
        "    def get_action(self, response):\n",
        "        invocation = self.agent_language.parse_response(response)\n",
        "        action = self.actions.get_action(invocation[\"tool\"])\n",
        "        return action, invocation\n",
        "\n",
        "    def should_terminate(self, response: str) -> bool:\n",
        "        action_def, _ = self.get_action(response)\n",
        "        return action_def.terminal\n",
        "\n",
        "    def set_current_task(self, memory: Memory, task: str):\n",
        "        memory.add_memory({\"type\": \"user\", \"content\": task})\n",
        "\n",
        "    def update_memory(self, memory: Memory, response: str, result: dict):\n",
        "        \"\"\"\n",
        "        Update memory with the agent's decision and the environment's response.\n",
        "        \"\"\"\n",
        "        new_memories = [\n",
        "            {\"type\": \"assistant\", \"content\": response},\n",
        "            {\"type\": \"user\", \"content\": json.dumps(result)}\n",
        "        ]\n",
        "        for m in new_memories:\n",
        "            memory.add_memory(m)\n",
        "\n",
        "    def prompt_llm_for_action(self, full_prompt: Prompt) -> str:\n",
        "        response = self.generate_response(full_prompt)\n",
        "        return response\n",
        "\n",
        "    def run(self, user_input: str, memory=None, max_iterations: int = 50) -> Memory:\n",
        "        \"\"\"\n",
        "        Execute the GAME loop for this agent with a maximum iteration limit.\n",
        "        \"\"\"\n",
        "        memory = memory or Memory()\n",
        "        self.set_current_task(memory, user_input)\n",
        "\n",
        "        for _ in range(max_iterations):\n",
        "            # Construct a prompt that includes the Goals, Actions, and the current Memory\n",
        "            prompt = self.construct_prompt(self.goals, memory, self.actions)\n",
        "\n",
        "            print(\"Agent thinking...\")\n",
        "            # Generate a response from the agent\n",
        "            response = self.prompt_llm_for_action(prompt)\n",
        "            print(f\"Agent Decision: {response}\")\n",
        "\n",
        "            # Determine which action the agent wants to execute\n",
        "            action, invocation = self.get_action(response)\n",
        "\n",
        "            # Execute the action in the environment\n",
        "            result = self.environment.execute_action(action, invocation[\"args\"])\n",
        "            print(f\"Action Result: {result}\")\n",
        "\n",
        "            # Update the agent's memory with information about what happened\n",
        "            self.update_memory(memory, response, result)\n",
        "\n",
        "            # Check if the agent has decided to terminate\n",
        "            if self.should_terminate(response):\n",
        "                break\n",
        "\n",
        "        return memory\n",
        "Now, let’s walk through how the GAME components work together in this agent architecture, explaining each part of agent loop.\n",
        "\n",
        "Step 1: Constructing the Prompt\n",
        "When the agent loop begins, it first constructs a prompt using the construct_prompt method:\n",
        "\n",
        "def construct_prompt(self, goals: List[Goal], memory: Memory, actions: ActionRegistry) -> Prompt:\n",
        "    \"\"\"Build prompt with memory context\"\"\"\n",
        "    return self.agent_language.construct_prompt(\n",
        "        actions=actions.get_actions(),\n",
        "        environment=self.environment,\n",
        "        goals=goals,\n",
        "        memory=memory\n",
        "    )\n",
        "This method leverages the AgentLanguage component to build a structured prompt containing:\n",
        "\n",
        "The agent’s goals (what it’s trying to accomplish)\n",
        "Available actions (tools the agent can use)\n",
        "Current memory context (conversation history and relevant information)\n",
        "Environment details (constraints and context for operation)\n",
        "We are going to discuss the AgentLanguage in more detail later. For now, what you need to know is that it is responsible for formatting the prompt that is sent to the LLM and parsing the response from the LLM. Most of the time, we are going to use function calling, so the parsing will just be reading the returned tool calls. However, the AgentLanguage can be changed to allow us to also take the same agent and implement it without function calling.\n",
        "\n",
        "Step 2: Generating a Response\n",
        "Next, the agent sends this prompt to the language model:\n",
        "\n",
        "def prompt_llm_for_action(self, full_prompt: Prompt) -> str:\n",
        "    response = self.generate_response(full_prompt)\n",
        "    return response\n",
        "The generate_response function is a simple python function provided during initialization. This abstraction allows the framework to work with different language models without changing the core loop. We will use LiteLLM to call the LLM, but you could easily swap this out for any other LLM provider.\n",
        "\n",
        "Step 3: Parsing the Response\n",
        "Once the language model returns a response, the agent parses it to identify the intended action. The parsing will generally be just getting the tool calls from the response, however the agent language gets to decide how this is done. Once the response is parsed, the agent can look up the action in the ActionRegistry:\n",
        "\n",
        "def get_action(self, response):\n",
        "    invocation = self.agent_language.parse_response(response)\n",
        "    action = self.actions.get_action(invocation[\"tool\"])\n",
        "    return action, invocation\n",
        "The action is the interface definition of what the agent “can” do. The invocation is the specific parameters that the agent has chosen to use for this action. The ActionRegistry allows the agent to look up the action by name, and the invocation provides the arguments needed to execute it. We could also add validation at this step to ensure that the invocation parameters match the action’s expected parameters.\n",
        "\n",
        "Step 4: Executing the Action\n",
        "The agent then executes the chosen action in the environment:\n",
        "\n",
        "# Execute the action in the environment\n",
        "result = self.environment.execute_action(action, invocation[\"args\"])\n",
        "The Environment handles the actual execution of the action, which might involve:\n",
        "\n",
        "Making API calls\n",
        "Reading/writing files\n",
        "Querying databases\n",
        "Processing data\n",
        "Actions are defined in the ActionRegistry but executed within the context of the Environment, which provides access to resources and handles the mechanics of execution.\n",
        "\n",
        "Step 5: Updating Memory\n",
        "After execution, the agent updates its memory with both its decision and the result:\n",
        "\n",
        "def update_memory(self, memory: Memory, response: str, result: dict):\n",
        "    \"\"\"\n",
        "    Update memory with the agent's decision and the environment's response.\n",
        "    \"\"\"\n",
        "    new_memories = [\n",
        "        {\"type\": \"assistant\", \"content\": response},\n",
        "        {\"type\": \"user\", \"content\": json.dumps(result)}\n",
        "    ]\n",
        "    for m in new_memories:\n",
        "        memory.add_memory(m)\n",
        "This creates a continuous record of the agent’s reasoning and actions, which becomes part of the context of future loop iterations. The memory serves both as a record of past actions and as context for future prompt construction.\n",
        "\n",
        "Step 6: Termination Check\n",
        "Finally, the agent checks if it should terminate the loop:\n",
        "\n",
        "def should_terminate(self, response: str) -> bool:\n",
        "    action_def, _ = self.get_action(response)\n",
        "    return action_def.terminal\n",
        "This allows certain actions (like a “terminate” action) to signal that the agent has finished its work.\n",
        "\n",
        "The Flow of Information Through the Loop\n",
        "To better understand how these components interact, let’s trace how information flows through a single iteration of the loop:\n",
        "\n",
        "The Memory provides context about what the user has asked the agent to do and past decisions and results from the agent loop\n",
        "The Goals define what the agent is trying to accomplish and rules on how to accomplish it\n",
        "The ActionRegistry defines what the agent can do and helps lookup the action to execute by name\n",
        "The AgentLanguage formats Memory, Actions, and Goals into a prompt for the LLM\n",
        "The LLM generates a response choosing an action\n",
        "The AgentLanguage parses the response into an action invocation, which will typically be extracted from tool calls\n",
        "The Environment executes the action with the given arguments\n",
        "The result is stored back in Memory\n",
        "The loop repeats with the updated memory until the agent calls a terminal tool or reaches the maximum number of iterations\n",
        "Creating Specialized Agents\n",
        "The beauty of this framework is that we can create entirely different agents by changing the GAME components without modifying the core loop:\n",
        "\n",
        "# A research agent\n",
        "research_agent = Agent(\n",
        "    goals=[Goal(\"Find and summarize information on topic X\")],\n",
        "    agent_language=ResearchLanguage(),\n",
        "    action_registry=ActionRegistry([SearchAction(), SummarizeAction(), ...]),\n",
        "    generate_response=openai_call,\n",
        "    environment=WebEnvironment()\n",
        ")\n",
        "\n",
        "# A coding agent\n",
        "coding_agent = Agent(\n",
        "    goals=[Goal(\"Write and debug Python code for task Y\")],\n",
        "    agent_language=CodingLanguage(),\n",
        "    action_registry=ActionRegistry([WriteCodeAction(), TestCodeAction(), ...]),\n",
        "    generate_response=anthropic_call,\n",
        "    environment=DevEnvironment()\n",
        ")\n",
        "Each agent operates using the same fundamental loop but exhibits completely different behaviors based on its GAME components."
      ],
      "metadata": {
        "id": "9SfO0vC0NgRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building a Simple Agent Framework 3\n",
        "Let’s go back to the file agent that we built earlier. The original implementation uses direct function calls and a lot of conditional logic in the agent loop. Let’s redo the implementation using our new framework.\n",
        "\n",
        "Define the Goals\n",
        "First, let’s define some goals for our file explorer agent:\n",
        "\n",
        "# Define clear goals for the agent\n",
        "goals = [\n",
        "    Goal(\n",
        "        priority=1,\n",
        "        name=\"Explore Files\",\n",
        "        description=\"Explore files in the current directory by listing and reading them\"\n",
        "    ),\n",
        "    Goal(\n",
        "        priority=2,\n",
        "        name=\"Terminate\",\n",
        "        description=\"Terminate the session when tasks are complete with a helpful summary\"\n",
        "    )\n",
        "]\n",
        "Create Actions Using the Framework\n",
        "Next, let’s convert our tool functions into properly structured Actions in our AgentRegistry:\n",
        "\n",
        "def list_files() -> List[str]:\n",
        "    \"\"\"List files in the current directory.\"\"\"\n",
        "    return os.listdir(\".\")\n",
        "\n",
        "def read_file(file_name: str) -> str:\n",
        "    \"\"\"Read a file's contents.\"\"\"\n",
        "    try:\n",
        "        with open(file_name, \"r\") as file:\n",
        "            return file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def terminate(message: str) -> str:\n",
        "    \"\"\"Terminate the agent loop and provide a summary message.\"\"\"\n",
        "    return message\n",
        "\n",
        "# Create and register the actions\n",
        "action_registry = ActionRegistry()\n",
        "\n",
        "action_registry.register(Action(\n",
        "    name=\"list_files\",\n",
        "    function=list_files,\n",
        "    description=\"Returns a list of files in the directory.\",\n",
        "    parameters={},\n",
        "    terminal=False\n",
        "))\n",
        "\n",
        "action_registry.register(Action(\n",
        "    name=\"read_file\",\n",
        "    function=read_file,\n",
        "    description=\"Reads the content of a specified file in the directory.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"file_name\": {\"type\": \"string\"}\n",
        "        },\n",
        "        \"required\": [\"file_name\"]\n",
        "    },\n",
        "    terminal=False\n",
        "))\n",
        "\n",
        "action_registry.register(Action(\n",
        "    name=\"terminate\",\n",
        "    function=terminate,\n",
        "    description=\"Terminates the conversation. Prints the provided message for the user.\",\n",
        "    parameters={\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"message\": {\"type\": \"string\"},\n",
        "        },\n",
        "        \"required\": [\"message\"]\n",
        "    },\n",
        "    terminal=True\n",
        "))\n",
        "Create and Run the Agent\n",
        "Now we can put it all together:\n",
        "\n",
        "\n",
        "# Create the agent\n",
        "file_explorer_agent = Agent(\n",
        "    goals=goals,\n",
        "    agent_language=agent_language,\n",
        "    action_registry=action_registry,\n",
        "    generate_response=generate_response,\n",
        "    environment=environment\n",
        ")\n",
        "\n",
        "# Run the agent\n",
        "user_input = input(\"What would you like me to do? \")\n",
        "final_memory = file_explorer_agent.run(user_input, max_iterations=10)\n",
        "\n",
        "# Print the final conversation if desired\n",
        "for item in final_memory.get_memories():\n",
        "    print(f\"\\n{item['type'].upper()}: {item['content']}\")\n",
        "Complete Implementation\n",
        "Here’s the full implementation using the GAME framework:\n",
        "\n",
        "def main():\n",
        "    # Define the agent's goals\n",
        "    goals = [\n",
        "        Goal(\n",
        "            priority=1,\n",
        "            name=\"Explore Files\",\n",
        "            description=\"Explore files in the current directory by listing and reading them\"\n",
        "        ),\n",
        "        Goal(\n",
        "            priority=2,\n",
        "            name=\"Terminate\",\n",
        "            description=\"Terminate the session when tasks are complete with a helpful summary\"\n",
        "        )\n",
        "    ]\n",
        "    \n",
        "    # Define tool functions\n",
        "    def list_files() -> List[str]:\n",
        "        \"\"\"List files in the current directory.\"\"\"\n",
        "        return os.listdir(\".\")\n",
        "\n",
        "    def read_file(file_name: str) -> str:\n",
        "        \"\"\"Read a file's contents.\"\"\"\n",
        "        try:\n",
        "            with open(file_name, \"r\") as file:\n",
        "                return file.read()\n",
        "        except FileNotFoundError:\n",
        "            return f\"Error: {file_name} not found.\"\n",
        "        except Exception as e:\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "    def terminate(message: str) -> str:\n",
        "        \"\"\"Terminate the agent loop and provide a summary message.\"\"\"\n",
        "        return message\n",
        "    \n",
        "    # Create action registry and register actions\n",
        "    action_registry = ActionRegistry()\n",
        "    \n",
        "    action_registry.register(Action(\n",
        "        name=\"list_files\",\n",
        "        function=list_files,\n",
        "        description=\"Returns a list of files in the directory.\",\n",
        "        parameters={},\n",
        "        terminal=False\n",
        "    ))\n",
        "    \n",
        "    action_registry.register(Action(\n",
        "        name=\"read_file\",\n",
        "        function=read_file,\n",
        "        description=\"Reads the content of a specified file in the directory.\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"file_name\": {\"type\": \"string\"}\n",
        "            },\n",
        "            \"required\": [\"file_name\"]\n",
        "        },\n",
        "        terminal=False\n",
        "    ))\n",
        "    \n",
        "    action_registry.register(Action(\n",
        "        name=\"terminate\",\n",
        "        function=terminate,\n",
        "        description=\"Terminates the conversation. Prints the provided message for the user.\",\n",
        "        parameters={\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"message\": {\"type\": \"string\"},\n",
        "            },\n",
        "            \"required\": [\"message\"]\n",
        "        },\n",
        "        terminal=True\n",
        "    ))\n",
        "    \n",
        "    # Define the agent language and environment\n",
        "    agent_language = AgentFunctionCallingActionLanguage()\n",
        "    environment = Environment()\n",
        "    \n",
        "    # Create the agent\n",
        "    file_explorer_agent = Agent(\n",
        "        goals=goals,\n",
        "        agent_language=agent_language,\n",
        "        action_registry=action_registry,\n",
        "        generate_response=generate_response,\n",
        "        environment=environment\n",
        "    )\n",
        "    \n",
        "    # Run the agent\n",
        "    user_input = input(\"What would you like me to do? \")\n",
        "    final_memory = file_explorer_agent.run(user_input, max_iterations=10)\n",
        "    \n",
        "    # Print the termination message (if any)\n",
        "    for item in final_memory.get_memories():\n",
        "        print(f\"\\nMemory: {item['content']}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "Key Differences and Benefits\n",
        "By converting our agent to the GAME framework, we gain several benefits:\n",
        "\n",
        "Better Organization: Each component has a clear purpose and is separated from others.\n",
        "Reusability: We can swap out components (like the actions or environment) without changing the core logic.\n",
        "Extensibility: New goals and actions can be added easily.\n",
        "Standard Interface: Using the Agent class gives us a consistent way to interact with different agents.\n",
        "Memory Management: The framework handles memory updates automatically.\n",
        "This structure also makes it easier to understand and maintain the code, especially as your agent grows in complexity.\n",
        "\n",
        "Using the Agent\n",
        "Once implemented, you can use your file explorer agent like this:\n",
        "\n",
        "What would you like me to do? Tell me what Python files are in this directory and summarize how they fit together.\n",
        "\n",
        "Agent thinking...\n",
        "Agent Decision: I'll help you explore the Python files in this directory.\n",
        "\n",
        "{\"tool_name\": \"list_files\", \"args\": {}}\n",
        "\n",
        "Action Result: {'tool_executed': True, 'result': ['file1.py', 'file2.py', 'main.py', ...], 'timestamp': '2025-03-02T12:34:56+0000'}\n",
        "\n",
        "{\"tool_name\": \"read_file\", \"args\": {\"file_name\": \"file1.py\"}}\n",
        "\n",
        "Action Result: {'tool_executed': True, 'result': '# This is file1.py\\n\\ndef hello_world():\\n    print(\"Hello, World!\")\\n\\nif __name__ == \"__main__\":\\n    hello_world()', 'timestamp': '2025-03-02T12:34:58+0000'}\n",
        "\n",
        "[Additional file readings...]\n",
        "\n",
        "{\"tool_name\": \"terminate\", \"args\": {\"message\": \"I've explored all Python files in this directory. Here's a summary: file1.py contains a simple hello_world function, file2.py implements a calculator class, and main.py imports both files and uses their functionality.\"}}\n",
        "\n",
        "...\n",
        "This structured approach makes it much easier to develop, maintain, and extend your agents over time."
      ],
      "metadata": {
        "id": "gd-tZoM9NklV"
      }
    }
  ]
}